{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23a435f-6c16-4f1b-af0a-0a5a8cc6b0bf",
   "metadata": {},
   "source": [
    "##### Todo\n",
    "- Review Week 3 practices and do them on notebooks\n",
    "- Review project examples and create possible structures for your report\n",
    "- Start working on your project proposal\n",
    "- Maybe schedule an office hours meeting so you can discuss futher final project details with any staff member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a48e5a2-3ce1-4740-b860-5e2a6f8431e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\sasu-\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sasu-\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sasu-\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sasu-\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sasu-\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bed8b81-d5aa-491c-a91e-5ae9ff2b2769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebafcc76-4be1-4e6b-b129-c551dd9ad1e3",
   "metadata": {},
   "source": [
    "## Categories to evaluate your models:\n",
    "# -Regression\n",
    "# -Classification\n",
    "# -Unsupervised\n",
    "# -Others (CV error, Heurustic Methods to find k, BLEU Score (NLP)\n",
    "Here we wil focus on:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf0920-24f8-4333-b882-65c6c7812cd2",
   "metadata": {},
   "source": [
    "# 1.Classification Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f496de-5053-4344-af10-5c09a6af7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator # allows u to create custom estimators/classifiers\n",
    "# making it compatible with scikit-learn's API & eg be used in pipelines,grid search & more\n",
    "\n",
    "class LeDummyClassifier(BaseEstimator): \n",
    "    # The model here is for sex prediction, a binary dummy (o vs 1)\n",
    "    def fit(seld, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( (X.shape[0], 1))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[1] = 1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c2582-6512-4717-85d7-a3fd19d26bad",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b141f-8230-4795-b573-d2e766eb9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepross null values\n",
    "def filling(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna(df['N'].mean(),inplace=True)\n",
    "    df['Embarked'].fillna(df['N'].mean(),inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "    \n",
    "# Delete features not needed\n",
    "def delete_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Calling transfor features previously mentioned\n",
    "def trasnform_features(df):\n",
    "    df = fillina(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be72ab8-48f3-4698-ab0c-fe00ad1e1137",
   "metadata": {},
   "source": [
    "# Checking out model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30a665-3399-44b1-bd13-51bf3350208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_Selection import train_test_split\n",
    "from skelarn.metrics import accuracy_score\n",
    "\n",
    "# calling out data, prepross dara, & then training & splitting model\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_tiranic_df = titanic_df,drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_titanic_df, y_titanic_df,\\\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "\n",
    "# Using dummy classifier model previously made\n",
    "leClass = LeDummyClassifier()\n",
    "leClass.fit(X_train, y_train)\n",
    "\n",
    "lePredictions = leClass.predict(X_test)\n",
    "print('DummyClass accuracy is\" : {0:.4f}'.format(accuracy_score(y_test, lePredictions)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a134f-fdd7-4fb4-b278-d6b445fac4e2",
   "metadata": {},
   "source": [
    "# The indicators that are used are (slides are helpful to describe this) :\n",
    "# -ACCURACY\n",
    "# -PRECISION\n",
    "# -RECALL/SENSITIVITY/TRUE POSITIVE RATE\n",
    "# -SPECIFCITY\n",
    "Next up:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47944a0f-f6c6-40c1-9a90-6bb5be313a84",
   "metadata": {},
   "source": [
    "# 2.Precision & Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564abd8e-5b56-4066-ac1c-b096f6716b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selectio import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metric import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class FeikClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "def predict(self,X)\n",
    "    return np.zeros( (len(X), 1) , dtype=bool)\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print('### digits.data.shape:', digits.data.shape)\n",
    "print(digits.target)\n",
    "print('### digits.target.shape:' , digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44e815-8c09-4313-9039-d488a39ae2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (digits.target ==7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data,y,random_state=11)\n",
    "feikClassf = FeikClassifier()\n",
    "feikClassf.fit(X_train,y_train)\n",
    "feik_pred = feikClassf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021927f5-d76a-46f8-b348-e62aad041406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Precision:\", precision_score(y_test, feik_pred)\n",
    "print(\"Recall:\", recall_score(y_test, feik_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dcdb59-bbd9-4b39-926a-06a000d982fb",
   "metadata": {},
   "source": [
    "# Getting a confusion matrix (for accuracy/ precision/ recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940c85b-2e1b-43b4-86a9-585c4c7c4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_classf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print('Accuracy: {0:4f}, Precision: {1:4f}, Recall: {2:4f}'.format(accuracy, precision, recall))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e476d79-2dea-42e7-a1e6-b8a26232af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,\\ \n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "logReg_clsf = LogisticRgression()\n",
    "\n",
    "logReg_clsf.fit(X_train, y_train)\n",
    "pred = logReg_clsf(X_test)\n",
    "get_classf_eval(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e2ad9-fb66-48d3-a042-a868dc80843f",
   "metadata": {},
   "source": [
    "# Plotting Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59f951-d348-42fd-a410-1d3c21810366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
    "\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "precision_recall_curve_plot( y_test, logReg_clsf.predict_proba(X_test)[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc7c83e-8f70-472a-95cf-4b19a195a679",
   "metadata": {},
   "source": [
    "# 3. F1 Score: Mixture of Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac797c-41d5-4e5f-98b2-5ac6659540e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mretics import f1_score\n",
    "f1= f1_score(y_test, pred)\n",
    "print('F1 Score: {0:4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226eb41-b6d8-42ee-af8d-f51b2efbdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred)\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion)\n",
    "    print('Accuracy: {0:4f}, Precision: {1:4f}, Recall: {2:4f}, F1: {3:4f}'.formati(accuracy, precision, recall, f1)\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def get_eval_by_threshold(y_test,pred_proba_c1,thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binzarizer(threshold=custom_threshold.fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.trasnfor(pred_proba_c1)\n",
    "        pront('Thresholds:', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "\n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "pred_proba = logReg_clsf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a9c76-5a21-456a-add5-fd3c90418353",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00617430-14cc-4bf8-a3c8-ee650cfa1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(y_test, pred_proba_c1):\n",
    "    # Calculate TRP, FPR per thresholds\n",
    "    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "\n",
    "    # Plot data\n",
    "    plt.plot(fprs, tprs, label='ROC')\n",
    "\n",
    "    # Linear line\n",
    "    plt.plot([0,1], [0,1], 'k--', label='Random')\n",
    "\n",
    "    # legend\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlom(0,1); plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )'; plt.ylabel('TPR( Revall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "roc_curve_plot(y_test, logReg_clsf.predict_proba(X_test)[:,1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82153b5-857b-451c-a66e-18704a1e44ca",
   "metadata": {},
   "source": [
    "# Calculating AUC (area under ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62797c02-fe2e-4434-af12-056a2b0a7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = logReg_clsf.predict_proba(X_test)[:,1]\n",
    "roc_score = roc_auc_score(y_test,pred_proba)\n",
    "print('ROC AUC Value: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fbd0c-8035-417c-a3b1-9e80d302b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "\n",
    "precision, recall, thresholds = precision_recakk_curve(y_pred, pred_proba_c1)\n",
    "\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(\"PR AUC\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0e7b7-2ade-495c-a28d-f4352e6d967d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
